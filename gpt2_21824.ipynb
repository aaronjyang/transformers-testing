{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import random\n",
    "\n",
    "# Initialize GPT-2.5 model and tokenizer\n",
    "model_name = \"gpt2-medium\"  # Adjust model size if needed\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add new pad token\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define categories and word lists\n",
    "categories = {\n",
    "    \"fruits\": [\"Apple\", \"Banana\", \"Orange\", \"Grape\", \"Pineapple\",\n",
    "    \"Watermelon\", \"Kiwi\", \"Strawberry\", \"Mango\", \"Cherry\"],\n",
    "    \"sleep\": [\"Bed\", \"Rest\", \"Tired\", \"Dream\", \"Pillow\",\n",
    "    \"Snore\", \"Night\", \"Sleepy\", \"Nap\", \"Insomnia\"],\n",
    "    # Add more categories and word lists as needed\n",
    "}\n",
    "\n",
    "# Define filler task (double-digit addition problems)\n",
    "filler_task = [\"12 + 34 =\", \"45 + 67 =\", \"89 + 21 =\", \"33 + 55 =\", \"78 + 99 =\",\n",
    "    \"11 + 88 =\", \"67 + 23 =\", \"42 + 56 =\", \"79 + 14 =\", \"35 + 49 =\"]\n",
    "\n",
    "# Experiment parameters\n",
    "#word_list_lengths = [10, 100, 1000]\n",
    "word_list_lengths = [10]\n",
    "#filler_lengths = [10, 100, 1000]\n",
    "filler_lengths = [10]\n",
    "\n",
    "# Set pad token ID\n",
    "pad_token_id = tokenizer.eos_token_id  # Assuming eos_token_id is the pad token ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response after learning words:\n",
      "Learn the following words: Cherry\n",
      "Strawberry\n",
      "Kiwi\n",
      "Mango\n",
      "Apple\n",
      "Watermelon\n",
      "Grape\n",
      "Orange\n",
      "Banana\n",
      "Pineapple. Please respond with 'Done' when you have finished processing.\n",
      "\n",
      "If you have any questions about the processing of your order, please contact us.\n",
      "\n",
      "Please note that we do not accept returns or exchanges.\n",
      "\n",
      "Model response after solving addition problems:\n",
      "Please solve the following addition problems: 35 + 49 =\n",
      "33 + 55 =\n",
      "11 + 88 =\n",
      "12 + 34 =\n",
      "42 + 56 =\n",
      "45 + 67 =\n",
      "78 + 99 =\n",
      "67 + 23 =\n",
      "79 + 14 =\n",
      "89 + 21 =........\n",
      "1\n",
      "Next, find the number of times that the given predicate was called in order to compute. This will allow you to compare each predicate to determine which is more likely. Consider the following function. It calls both its arguments once: (defn add-fn [& args]...) (defn multiply-fn [& args]...) (defn divide-fn [& args]...) (defn divide-p [& args]...) Finally, take note that the first, middle, and last arguments to this function are also calls to the function it is evaluating.\n",
      "The function will be called only once within the function body, but since there is no\n",
      "\n",
      "Model response after recalling words:\n",
      "Now recall the words that you were given earlier. Please list all of the words that you remember?\n",
      "\n",
      "You will recall that the words that you are given are the words that you have been given.\n",
      "\n",
      "Now remember that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that the words that you have been given are the words that you have been given.\n",
      "\n",
      "You will recall that\n",
      "Model response after learning words:\n",
      "Learn the following words: Snore\n",
      "Bed\n",
      "Dream\n",
      "Pillow\n",
      "Nap\n",
      "Insomnia\n",
      "Rest\n",
      "Tired\n",
      "Night\n",
      "Sleepy. Please respond with 'Done' when you have finished processing.\n",
      "1. What is your name?\n",
      "2. What is your occupation?\n",
      "3. What is your age?\n",
      "4. What is your sex?\n",
      "5. What is your religion?\n",
      "6. What is your job?\n",
      "7. What is your profession?\n",
      "8. What is your job title?\n",
      "9. What is your occupation?\n",
      "10. What is your age?\n",
      "11. What is your sex?\n",
      "12. What is your religion?\n",
      "13. What is your job title?\n",
      "14. What is your occupation?\n",
      "15. What is your job title?\n",
      "16. What is your age?\n",
      "17. What is your sex?\n",
      "18. What is your religion?\n",
      "19. What is your job title?\n",
      "\n",
      "\n",
      "Model response after solving addition problems:\n",
      "Please solve the following addition problems: 11 + 88 =\n",
      "45 + 67 =\n",
      "89 + 21 =\n",
      "12 + 34 =\n",
      "35 + 49 =\n",
      "67 + 23 =\n",
      "42 + 56 =\n",
      "33 + 55 =\n",
      "78 + 99 =\n",
      "79 + 14 =.. (We are using the 'a' argument in our example because of the number of spaces.) The first difficulty for these two problems is to show that the two adder solutions are both a 2^2 plus 1. You can find all the solutions to these problems, starting with the problem #1 and increasing from there, in the appendix of this book. (The appendix is not online yet, but you can download a PDF of it with the code below.) The solution to the problem 1 is easy to remember, as it is found in section 7 of chapter 5, which is also known as solving adder problems in the book \"Additive Algebra in Mathematics\". This is another solution to the Add\n",
      "\n",
      "Model response after recalling words:\n",
      "Now recall the words that you were given earlier. Please list all of the words that you remember?\n",
      "\n",
      "The word that you have been given is the word that you will be given.\n",
      "\n",
      "Now that you have been given the word that you will be given, what is it?\n",
      "\n",
      "It is the word that you have been given.\n",
      "\n",
      "It is the word that you have been given.\n",
      "\n",
      "Now, I want you to take a moment to think about what the word that you have been given is. What is it?\n",
      "\n",
      "It is the word that you have been given.\n",
      "\n",
      "It is the word that you have been given.\n",
      "\n",
      "Now, it is the word that you have been given.\n",
      "\n",
      "Now, it is the word that you have been given.\n",
      "\n",
      "Now, it is the word that you have been given.\n",
      "\n",
      "Now, it is the word that you have been given.\n",
      "\n",
      "Now, it is the word that you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Experiment loop\n",
    "for category, word_list in categories.items():\n",
    "    for word_list_length in word_list_lengths:\n",
    "        for filler_length in filler_lengths:\n",
    "            # Generate word list (excluding lure word) and filler task for this iteration\n",
    "            selected_words = random.sample(word_list, word_list_length)  # Exclude one word for the lure\n",
    "            selected_fillers = random.sample(filler_task, filler_length)\n",
    "            word_list_text = \"\\n\".join(selected_words)\n",
    "            filler_task_text = \"\\n\".join(selected_fillers)\n",
    "            \n",
    "            # Input 1: Learning the words\n",
    "            input_text_1 = f\"Learn the following words: {word_list_text}. Please respond with 'Done' when you have finished processing.\"\n",
    "\n",
    "            # Tokenize and encode input text for learning words\n",
    "            input_ids_1 = tokenizer.encode(input_text_1, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            # Generate model response for learning words\n",
    "            with torch.no_grad():\n",
    "                output_1 = model.generate(input_ids_1, \n",
    "                                          max_length=200, \n",
    "                                          pad_token_id=pad_token_id,\n",
    "                                          num_return_sequences=1,\n",
    "                                          temperature=0.5,  # Adjust temperature (default is 1.0)\n",
    "                                          top_k=40,  # Adjust top_k (default is 50)\n",
    "                                          top_p=.8,\n",
    "                                          do_sample=True)  # Adjust top_p (default is 1.0))\n",
    "\n",
    "            # Decode and print model response for learning words\n",
    "            decoded_output_1 = tokenizer.decode(output_1[0], skip_special_tokens=True)\n",
    "            print(\"Model response after learning words:\")\n",
    "            print(decoded_output_1)\n",
    "            \n",
    "            # Input 2: Solving double-digit addition problems\n",
    "            input_text_2 = f\"Please solve the following addition problems: {filler_task_text}.\"\n",
    "\n",
    "            # Tokenize and encode input text for addition problems\n",
    "            input_ids_2 = tokenizer.encode(input_text_2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            # Generate model response for addition problems\n",
    "            with torch.no_grad():\n",
    "                output_2 = model.generate(input_ids_2, max_length=200, \n",
    "                                          pad_token_id=pad_token_id, \n",
    "                                          num_return_sequences=1,\n",
    "                                          temperature=0.9,  # Adjust temperature (default is 1.0)\n",
    "                                          top_k=50,  # Adjust top_k (default is 50)\n",
    "                                          top_p=1.0,\n",
    "                                          do_sample=True)  # Adjust top_p (default is 1.0)))\n",
    "\n",
    "            # Decode and print model response for addition problems\n",
    "            decoded_output_2 = tokenizer.decode(output_2[0], skip_special_tokens=True)\n",
    "            print(\"\\nModel response after solving addition problems:\")\n",
    "            print(decoded_output_2)\n",
    "            \n",
    "            # Input 3: Recalling the words\n",
    "            input_text_3 = f\"Now recall the words that you were given earlier. Please list all of the words that you remember?\"\n",
    "\n",
    "            # Tokenize and encode input text for recalling words\n",
    "            input_ids_3 = tokenizer.encode(input_text_3, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            # Generate model response for recalling words\n",
    "            with torch.no_grad():\n",
    "                output_3 = model.generate(input_ids_3, max_length=200, \n",
    "                                          pad_token_id=pad_token_id, \n",
    "                                          num_return_sequences=1,\n",
    "                                          temperature=0.9,  # Adjust temperature (default is 1.0)\n",
    "                                          top_k=100,  # Adjust top_k (default is 50)\n",
    "                                          top_p=.5,\n",
    "                                          do_sample=True)  # Adjust top_p (default is 1.0)))\n",
    "\n",
    "            # Decode and print model response for recalling words\n",
    "            decoded_output_3 = tokenizer.decode(output_3[0], skip_special_tokens=True)\n",
    "            print(\"\\nModel response after recalling words:\")\n",
    "            print(decoded_output_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
